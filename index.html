<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Détection des Doigts Levés</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/hand-pose-detection"></script>
  <style>
    body {
      font-family: Arial, sans-serif;
      text-align: center;
      padding: 20px;
    }
    video, canvas {
      max-width: 100%;
      border: 2px solid #ccc;
      border-radius: 10px;
      margin-top: 20px;
    }
    button {
      margin-top: 10px;
      padding: 10px 20px;
      background-color: #4CAF50;
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
    }
    button:hover {
      background-color: #45a049;
    }
    .result {
      margin-top: 20px;
      font-size: 20px;
      color: #333;
    }
  </style>
</head>
<body>
  <h1>Détection des Doigts Levés</h1>
  <video id="camera" autoplay playsinline></video>
  <canvas id="snapshotCanvas" style="display: none;"></canvas>
  <div class="result" id="result">Nombre de doigts levés : --</div>
  <button id="captureButton">Analyser les Doigts</button>

  <script>
    const video = document.getElementById('camera');
    const resultDisplay = document.getElementById('result');
    const captureButton = document.getElementById('captureButton');

    let model;

    // Démarrer la caméra
    async function startCamera() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;
      } catch (error) {
        alert('Impossible d’accéder à la caméra : ' + error.message);
      }
    }

    // Charger le modèle Handpose
    async function loadModel() {
      model = await handpose.load();
      console.log('Modèle Handpose chargé.');
    }

    // Détecter les doigts levés
    async function detectFingers() {
      const predictions = await model.estimateHands(video);

      if (predictions.length > 0) {
        const hand = predictions[0];
        const landmarks = hand.landmarks;

        // Indices des jointures clés pour détecter les doigts
        const fingers = [
          [8, 6, 5], // Index
          [12, 10, 9], // Majeur
          [16, 14, 13], // Annulaire
          [20, 18, 17], // Auriculaire
          [4, 3, 2], // Pouce
        ];

        let raisedFingers = 0;

        fingers.forEach((finger) => {
          const [tip, middle, base] = finger;
          if (landmarks[tip][1] < landmarks[middle][1] && landmarks[middle][1] < landmarks[base][1]) {
            raisedFingers++;
          }
        });

        // Afficher le nombre de doigts levés
        resultDisplay.innerText = `Nombre de doigts levés : ${raisedFingers}`;
      } else {
        resultDisplay.innerText = 'Aucune main détectée.';
      }
    }

    // Ajouter un événement au bouton d'analyse
    captureButton.addEventListener('click', detectFingers);

    // Lancer la caméra et charger le modèle au démarrage
    startCamera();
    loadModel();
  </script>
</body>
</html>
